---
layout: post
title: Why chat and RAG don't mix
date: 2025-03-26 16:40:16
description: 
tags: 
categories: 
---

Chat interfaces have become the default for LLM interactions due to their simplicity and familiarity. Users type natural language queries and receive natural language responses without learning specialized commands or workflows. ChatGPT has trained us well.

However, this simplicity creates a technical challenge for AI application builders who want to add document interaction capabilities to their apps: while users approach chat expecting comprehensive document interaction capabilities, standard RAG implementations are narrowly optimized for factoid question answering. They fail on a wide variety of seemingly simple tasks. Let's discuss why.

### Technical Limitations of Standard RAG

Traditional RAG architectures excel at extracting discrete pieces of information from documents: "What was our Q3 revenue?" or "When did we change our refund policy?" They operate by chunking documents, embedding those chunks, retrieving relevant sections via vector similarity, and providing these as context to the LLM. This works well when there is an answer to be found directly in the documents, and when that answer is contained in a relatively small pieces of text.

However, users frequently go far beyond the narrow scope of tasks RAG systems are designed to handle. Here are a few examples of common document tasks that standard RAG isn't designed to handle:

- Document summarization
    - This is an extremely simple sounding use case, and it's the go-to "test prompt" for many users when they first try a new AI app that allows for uploading their docs. But it generally won't work with a pure RAG approach.
- Comparative analyses (necessitating structured comparison between multiple documents)
    - This will work well with certain types of queries for some RAG implementations, but not all.
- Pattern identification (requiring analysis across document collections)
    - "How have analyst opinions about NVDA changed over the last four quarters?"
- Multi-step reasoning tasks
    - "Read this policy document to understand the qualification requirements and then read this other document with my information to figure out if I qualify."

These operations fundamentally exceed what retrieval-based architectures were designed to handle. The core issue isn't implementation quality but rather architectural limitations: standard RAG was never engineered to support the full spectrum of document-centric operations users attempt to perform. Using a chat interface exacerbates this problem because users have been conditioned to view chat as a do-it-all UI. Why wouldn't "chat, but with my docs" be able to do everything chat can do, but with my docs as context?

This architectural mismatch leads to inconsistent system performance. When users request operations that align with the retrieval paradigm, the system performs well. When they request operations requiring document-level understanding or complex transformations, the same system falters. The result is unpredictable behavior from the user perspective, as the system's capabilities don't align with the affordances suggested by the chat interface.

### Implementation Alternatives

Two technical approaches can address this fundamental architecture-expectation gap:

**1. Interface Specialization**

This approach replaces the general chat interface with purpose-built UI flows for specific document operations. Each specialized interface can implement the optimal technical approach for its specific function:

- Dedicated summarization modules with document-level context management
- Structured comparison views with explicit document alignment algorithms
- Transformation interfaces with specialized prompt engineering

This creates a more predictable user experience by making system capabilities explicit. Your users are much less likely to try to do something the system isn't designed to handle. I like to think of this approach as "putting the UX on rails."

**2. Agent-Based Architecture**

Alternatively, a more sophisticated agent-based architecture can maintain the chat interface while expanding its capabilities. In this model:

- RAG becomes one tool out of many
- The agent analyzes user requests to determine required operations
- Specialized modules are invoked based on operation type
- Results are composed into coherent responses

This approach preserves interface simplicity while implementing a more robust technical architecture behind the scenes. It requires more complex orchestration logic but delivers a more consistent user experience. This approach has its drawbacks, though. First, it takes more engineering effort upfront to get a reliable product up and running. Second, it's generally slower and more expensive, which has both UX and financial impacts. And finally, it's never going to be as reliable as a more specialized interface that only does one or two things.

### Which approach should you pick?

Your first choice should always be interface specialization. If you're building an AI application and its name isn't ChatGPT, then your whole reason for existing is to build something more specialized than ChatGPT. You're not going to beat OpenAI at their own game. You might be specializing horizontally (marketing automation platform) or vertically (AI for financial advisors). Either way, you should be able to come up with user flows that are more purpose-built than "type into this chat box and get a response."

Now you may still want to layer on agentic capabilities within a more specialized UI. But that should be Step 2, not Step 1.